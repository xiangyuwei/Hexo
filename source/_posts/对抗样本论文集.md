#title

title: 对抗样本论文
# 所属分类

categories:

- 深度学习

# 标签(多个标签如下所示)

tags:

- 深度学习

- 对抗样本


------
## 深度学习
###１、2014-laining and Harnessing Adversarial Examples（对抗样本的解释和利用）”[[ArXiv](http://arxiv.org/abs/1412.6572)][[code](https://github.com/rodgzilla/machine_learning_adversarial_examples)][[code](https://github.com/tensorflow/cleverhans/blob/master/cleverhans/attacks.py)]




###２、2015-DeepFool: a simple and accurate method to fool deep neural networks [[ArXiv](http://arxiv.org/abs/1511.04599)][[code](https://github.com/tensorflow/cleverhans/blob/master/cleverhans/attacks.py)]


###３、2015-The Limitations of Deep Learning in Adversarial Settings[[ArXiv](http://arxiv.org/abs/1511.07528)][[code](https://github.com/tensorflow/cleverhans)]
### ４、2015-Distributional Smoothing with Virtual Adversarial Training [[ArXiv](http://arxiv.org/abs/1507.00677)][[code](https://github.com/tensorflow/cleverhans/blob/master/cleverhans/attacks.py)]


### ５、2016-Exploring the space of adversarial images
[[ArXiv](http://arxiv.org/abs/1510.05328)][[code](https://github.com/xiangyuwei/adversarial-1)]-lua

###６、2016-Adversarial Machine Learning at Scale[[ArXiv](http://arxiv.org/abs/1611.01236)][[code](https://github.com/tensorflow/cleverhans/tree/master/examples/nips17_adversarial_competition/sample_defenses/adv_inception_v3)]

###７、2016-Delving into Transferable Adversarial Examples and Black-box Attacks [[ArXiv](http://arxiv.org/abs/1611.02770)][[code](https://github.com/sunblaze-ucb/transferability-advdnn-pub)]

### ８、2016-Practical Black-Box Attacks against Machine Learning[[ArXiv](http://arxiv.org/abs/1602.02697)][[code](https://github.com/tensorflow/cleverhans/blob/master/cleverhans_tutorials/mnist_blackbox.py)]

###９、2016-Adversarial examples in the physical world [[ArXiv](http://arxiv.org/abs/1607.02533)][[code](https://github.com/tensorflow/cleverhans/tree/master/examples/nips17_adversarial_competition/sample_targeted_attacks/iter_target_class)][[code](https://github.com/tensorflow/cleverhans/blob/master/cleverhans/attacks.py)]

###10、2016-Simple Black-Box Adversarial Perturbations for Deep Networks[[ArXiv](http://arxiv.org/abs/1612.06299)]

###11、2017-Towards Evaluating the Robustness of Neural Networks[[ArXiv](http://arxiv.org/abs/608.04644)][[code](https://github.com/xiangyuwei/nn_robust_attacks)][[code](https://github.com/tensorflow/cleverhans/blob/master/cleverhans/attacks.py)]


###12、2017-Fast Feature Fool: A data independent approach to universal adversarial perturbations[[ArXiv](http://arxiv.org/abs/1707.05572)][[code](https://github.com/xiangyuwei/fast-feature-fool)]

###13、2017-Towards Deep Learning Models Resistant to Adversarial Attacks[[ArXiv](http://arxiv.org/abs/1706.06083)][[code](https://github.com/tensorflow/cleverhans/blob/master/cleverhans/attacks.py)]

###14、2017-Towards Deep Learning Models Resistant to Adversarial Attacks[[ArXiv](http://arxiv.org/abs/1705.07204)][[code](https://github.com/tensorflow/cleverhans/tree/master/examples/nips17_adversarial_competition/sample_defenses/ens_adv_inception_resnet_v2)]

###15、S. Zagoruyko. Are deep learning algorithms easily hackable?[[code](http://coxlab.github.io/ostrichinator)]


## 机器学习
### 16、2006-Can machine learning be secure?[[paper](http://portal.acm.org/citation.cfm?doid=1128817.1128824)]

### 17、2011-Adversarial machine learning

### 18、Take two software updates and see me in the morning: The Case for Software Security Evaluations of Medical Devices [[paper](http://www.contrib.andrew.cmu.edu/~ppoosank/papers/hanna-aed-healthsec11.pdf)]
### 19、Adversarial AI
###20、2017-机器学习安全性问题及其防御技术研究综述
### 21、Concrete Problems in AI Safety[[ArXiv](http://arxiv.org/abs/1606.06565)]
##GAN和对抗样本

### 1、2017-APE-GAN : Adversarial Perturbation Elimination with GAN[[ArXiv](http://arxiv.org/abs/1707.05474v3)] 

### 2、2017-Generative Adversarial Trainer : Defense to Adversarial Perturbations with GAN[[ArXiv](http://arxiv.org/abs/1705.03387v1)]

### ３、2017-Generating Adversarial Malware Examples for Black-Box Attacks Based on GAN[[ArXiv](http://arxiv.org/abs/1702.05983)]

### ４、2017-Adversarial examples for generative models[[ArXiv](http://arxiv.org/abs/1702.06832)]　　